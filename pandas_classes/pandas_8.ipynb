{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping and Aggregating - Analyzing and Exploring Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = pd.read_csv('Data/administrative-divisions/Region.csv', index_col='region_id')\n",
    "district = pd.read_csv('Data/administrative-divisions/Districts.csv', index_col='district_id', dtype={'district_id':'Int64', 'old_region' : 'Int64', 'new_region':'Int64'})\n",
    "local_types = pd.read_csv('Data/administrative-divisions/LocalBodyTypes.csv', index_col='local_body_type_id')\n",
    "local_bodies = pd.read_csv('Data/administrative-divisions/localBodies.csv', index_col='local_body_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1103], dtype='int64', name='region_id')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter1 = (region['Region'] == 'Bagmati')    &  (region['old_new'] == 1)\n",
    "filter1_index = region.loc[filter1].index\n",
    "filter1_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>district_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100108</th>\n",
       "      <td>Sindhupalchok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100206</th>\n",
       "      <td>Sindhuli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100107</th>\n",
       "      <td>Rasuwa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100204</th>\n",
       "      <td>Ramechhap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100106</th>\n",
       "      <td>Nuwakot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100303</th>\n",
       "      <td>Makwanpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100105</th>\n",
       "      <td>Lalitpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100104</th>\n",
       "      <td>Kavrepalanchok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100103</th>\n",
       "      <td>Kathmandu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100202</th>\n",
       "      <td>Dolakha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100102</th>\n",
       "      <td>Dhading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100302</th>\n",
       "      <td>Chitwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100101</th>\n",
       "      <td>Bhaktapur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   District\n",
       "district_id                \n",
       "100108        Sindhupalchok\n",
       "100206             Sindhuli\n",
       "100107               Rasuwa\n",
       "100204            Ramechhap\n",
       "100106              Nuwakot\n",
       "100303            Makwanpur\n",
       "100105             Lalitpur\n",
       "100104       Kavrepalanchok\n",
       "100103            Kathmandu\n",
       "100202              Dolakha\n",
       "100102              Dhading\n",
       "100302              Chitwan\n",
       "100101            Bhaktapur"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_dis_filter = district['new_region'] == filter1_index[0]\n",
    "bagmati_districts = district.loc[bag_dis_filter, ['District']]\n",
    "bagmati_districts.sort_values(by='District', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([100104], dtype='object', name='district_id')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find all the local bodies of Kavrepalanchok\n",
    "kavrefilter = (bagmati_districts['District'] == 'Kavrepalanchok')\n",
    "kavre_index = bagmati_districts.loc[kavrefilter].index\n",
    "kavre_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_body</th>\n",
       "      <th>local_body_type_id</th>\n",
       "      <th>max_ward</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_body_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001045001</th>\n",
       "      <td>Banepa</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001045002</th>\n",
       "      <td>Dhulikhel</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001045003</th>\n",
       "      <td>Panauti</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001047001</th>\n",
       "      <td>Anekot</td>\n",
       "      <td>107</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001047002</th>\n",
       "      <td>Balthali</td>\n",
       "      <td>107</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101045161</th>\n",
       "      <td>Namobuddha</td>\n",
       "      <td>105</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101045162</th>\n",
       "      <td>Panauti</td>\n",
       "      <td>105</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101045163</th>\n",
       "      <td>Panchkhal</td>\n",
       "      <td>105</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101049466</th>\n",
       "      <td>Roshi</td>\n",
       "      <td>119</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101049462</th>\n",
       "      <td>Temal</td>\n",
       "      <td>119</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               local_body  local_body_type_id  max_ward\n",
       "local_body_id                                          \n",
       "1001045001         Banepa                 105       NaN\n",
       "1001045002      Dhulikhel                 105       NaN\n",
       "1001045003        Panauti                 105       NaN\n",
       "1001047001         Anekot                 107       9.0\n",
       "1001047002       Balthali                 107       9.0\n",
       "...                   ...                 ...       ...\n",
       "1101045161     Namobuddha                 105      11.0\n",
       "1101045162        Panauti                 105      12.0\n",
       "1101045163      Panchkhal                 105      13.0\n",
       "1101049466          Roshi                 119      12.0\n",
       "1101049462          Temal                 119       9.0\n",
       "\n",
       "[102 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kavre_local_filter = (local_bodies['district_id'] == kavre_index[0])\n",
    "kavre_local = local_bodies.loc[kavre_local_filter, ['local_body', 'local_body_type_id', 'max_ward']]\n",
    "kavre_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anish</td>\n",
       "      <td>Khadka</td>\n",
       "      <td>anishramish56@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ramish</td>\n",
       "      <td>Mainali</td>\n",
       "      <td>mainaliramish89@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samish</td>\n",
       "      <td>Shrestha</td>\n",
       "      <td>shresthasamish28@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bamish</td>\n",
       "      <td>Karki</td>\n",
       "      <td>bamishkarki819@gmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bamish</td>\n",
       "      <td>Mainali</td>\n",
       "      <td>bamishmainali78@gmail.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    first      last                       email\n",
       "0   Anish    Khadka     anishramish56@gmail.com\n",
       "1  Ramish   Mainali   mainaliramish89@gmail.com\n",
       "2  Samish  Shrestha  shresthasamish28@gmail.com\n",
       "3  Bamish     Karki    bamishkarki819@gmail.com\n",
       "4  Bamish   Mainali   bamishmainali78@gmail.com"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Working with example dataframe\n",
    "people = {\n",
    "    \"first\" : [\"Anish\", \"Ramish\", \"Samish\", \"Bamish\", \"Bamish\"],\n",
    "    \"last\" : [\"Khadka\", \"Mainali\", \"Shrestha\", \"Karki\", \"Mainali\"],\n",
    "    \"email\" : [\"anishramish56@gmail.com\", \"mainaliramish89@gmail.com\", \n",
    "               \"shresthasamish28@gmail.com\", \"bamishkarki819@gmail.com\",\n",
    "               \"bamishmainali78@gmail.com\"]\n",
    "}\n",
    "mydf = pd.DataFrame(people)\n",
    "mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation : multiple pieces of data into a single result\n",
    "# df['column_name'].median()\n",
    "# df.median() # For entire data frame where there is numerical value\n",
    "# df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading real data\n",
    "df = pd.read_csv('Data/stack-overflow-developer-survey-2024/survey_results_public.csv', index_col='ResponseId')\n",
    "schema_df = pd.read_csv('Data/stack-overflow-developer-survey-2024/survey_results_schema.csv', index_col='qname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompTotal</th>\n",
       "      <th>WorkExp</th>\n",
       "      <th>JobSatPoints_1</th>\n",
       "      <th>JobSatPoints_4</th>\n",
       "      <th>JobSatPoints_5</th>\n",
       "      <th>JobSatPoints_6</th>\n",
       "      <th>JobSatPoints_7</th>\n",
       "      <th>JobSatPoints_8</th>\n",
       "      <th>JobSatPoints_9</th>\n",
       "      <th>JobSatPoints_10</th>\n",
       "      <th>JobSatPoints_11</th>\n",
       "      <th>ConvertedCompYearly</th>\n",
       "      <th>JobSat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.374000e+04</td>\n",
       "      <td>29658.000000</td>\n",
       "      <td>29324.000000</td>\n",
       "      <td>29393.000000</td>\n",
       "      <td>29411.000000</td>\n",
       "      <td>29450.000000</td>\n",
       "      <td>29448.00000</td>\n",
       "      <td>29456.000000</td>\n",
       "      <td>29456.000000</td>\n",
       "      <td>29450.000000</td>\n",
       "      <td>29445.000000</td>\n",
       "      <td>2.343500e+04</td>\n",
       "      <td>29126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.963841e+145</td>\n",
       "      <td>11.466957</td>\n",
       "      <td>18.581094</td>\n",
       "      <td>7.522140</td>\n",
       "      <td>10.060857</td>\n",
       "      <td>24.343232</td>\n",
       "      <td>22.96522</td>\n",
       "      <td>20.278165</td>\n",
       "      <td>16.169432</td>\n",
       "      <td>10.955713</td>\n",
       "      <td>9.953948</td>\n",
       "      <td>8.615529e+04</td>\n",
       "      <td>6.935041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.444117e+147</td>\n",
       "      <td>9.168709</td>\n",
       "      <td>25.966221</td>\n",
       "      <td>18.422661</td>\n",
       "      <td>21.833836</td>\n",
       "      <td>27.089360</td>\n",
       "      <td>27.01774</td>\n",
       "      <td>26.108110</td>\n",
       "      <td>24.845032</td>\n",
       "      <td>22.906263</td>\n",
       "      <td>21.775652</td>\n",
       "      <td>1.867570e+05</td>\n",
       "      <td>2.088259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000e+04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.271200e+04</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.100000e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.500000e+04</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.079715e+05</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+150</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.625660e+07</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CompTotal       WorkExp  JobSatPoints_1  JobSatPoints_4  \\\n",
       "count   3.374000e+04  29658.000000    29324.000000    29393.000000   \n",
       "mean   2.963841e+145     11.466957       18.581094        7.522140   \n",
       "std    5.444117e+147      9.168709       25.966221       18.422661   \n",
       "min     0.000000e+00      0.000000        0.000000        0.000000   \n",
       "25%     6.000000e+04      4.000000        0.000000        0.000000   \n",
       "50%     1.100000e+05      9.000000       10.000000        0.000000   \n",
       "75%     2.500000e+05     16.000000       22.000000        5.000000   \n",
       "max    1.000000e+150     50.000000      100.000000      100.000000   \n",
       "\n",
       "       JobSatPoints_5  JobSatPoints_6  JobSatPoints_7  JobSatPoints_8  \\\n",
       "count    29411.000000    29450.000000     29448.00000    29456.000000   \n",
       "mean        10.060857       24.343232        22.96522       20.278165   \n",
       "std         21.833836       27.089360        27.01774       26.108110   \n",
       "min          0.000000        0.000000         0.00000        0.000000   \n",
       "25%          0.000000        0.000000         0.00000        0.000000   \n",
       "50%          0.000000       20.000000        15.00000       10.000000   \n",
       "75%         10.000000       30.000000        30.00000       25.000000   \n",
       "max        100.000000      100.000000       100.00000      100.000000   \n",
       "\n",
       "       JobSatPoints_9  JobSatPoints_10  JobSatPoints_11  ConvertedCompYearly  \\\n",
       "count    29456.000000     29450.000000     29445.000000         2.343500e+04   \n",
       "mean        16.169432        10.955713         9.953948         8.615529e+04   \n",
       "std         24.845032        22.906263        21.775652         1.867570e+05   \n",
       "min          0.000000         0.000000         0.000000         1.000000e+00   \n",
       "25%          0.000000         0.000000         0.000000         3.271200e+04   \n",
       "50%          5.000000         0.000000         0.000000         6.500000e+04   \n",
       "75%         20.000000        10.000000        10.000000         1.079715e+05   \n",
       "max        100.000000       100.000000       100.000000         1.625660e+07   \n",
       "\n",
       "             JobSat  \n",
       "count  29126.000000  \n",
       "mean       6.935041  \n",
       "std        2.088259  \n",
       "min        0.000000  \n",
       "25%        6.000000  \n",
       "50%        7.000000  \n",
       "75%        8.000000  \n",
       "max       10.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65000.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ConvertedCompYearly'].median() # median salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23435"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ConvertedCompYearly'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cycle goes on\n",
    "# Never improving myself with this attitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the life going\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Read CSV File\n",
    "def read_csv_example():\n",
    "    df = pd.read_csv('Data/stack-overflow-developer-survey-2024/survey_results_public.csv')\n",
    "    print(\"First 5 rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "# 2. Display First N Rows\n",
    "def head_example(df):\n",
    "    print(\"First 10 rows:\")\n",
    "    print(df.head(10))\n",
    "\n",
    "# 3. Get DataFrame Info\n",
    "def info_example(df):\n",
    "    print(\"DataFrame Info:\")\n",
    "    df.info()\n",
    "\n",
    "# 4. Summary Statistics\n",
    "def describe_example(df):\n",
    "    print(\"Summary Statistics:\")\n",
    "    print(df.describe())\n",
    "\n",
    "# 5. Check for Missing Values\n",
    "def check_missing_values(df):\n",
    "    print(\"Missing Values Count:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "# 6. Fill Missing Values\n",
    "def fill_missing_values(df):\n",
    "    df['column_name'] = df['column_name'].fillna(0)  # Replace NaN with 0\n",
    "    print(\"Filled Missing Values:\")\n",
    "    print(df.head())\n",
    "\n",
    "# 7. Group Data by Column\n",
    "def group_by_example(df):\n",
    "    grouped = df.groupby('category').sum()\n",
    "    print(\"Grouped Data:\")\n",
    "    print(grouped)\n",
    "\n",
    "# 8. Sort Data by Column\n",
    "def sort_values_example(df):\n",
    "    sorted_df = df.sort_values(by='column_name', ascending=True)\n",
    "    print(\"Sorted Data:\")\n",
    "    print(sorted_df.head())\n",
    "\n",
    "# 9. Apply Function to Column\n",
    "def apply_example(df):\n",
    "    df['new_col'] = df['col'].apply(lambda x: x * 2)\n",
    "    print(\"After Applying Function:\")\n",
    "    print(df.head())\n",
    "\n",
    "# 10. Merge Two DataFrames\n",
    "def merge_example(df1, df2):\n",
    "    merged = pd.merge(df1, df2, on='common_column', how='inner')\n",
    "    print(\"Merged DataFrame:\")\n",
    "    print(merged.head())\n",
    "\n",
    "\n",
    "# Learning next important pands functions for the day\n",
    "\n",
    "# 11. Concatenate DataFrames\n",
    "def concat_example(df1, df2):\n",
    "    combined = pd.concat([df1, df2], axis=0)\n",
    "    print(\"Concatenated DataFrame:\")\n",
    "    print(combined.head())\n",
    "\n",
    "# 12. Create Pivot Table\n",
    "def pivot_table_example(df):\n",
    "    pivot = pd.pivot_table(df, values='value_col', index='index_col', columns='category_col', aggfunc='sum')\n",
    "    print(\"Pivot Table:\")\n",
    "    print(pivot)\n",
    "\n",
    "# 13. Check for Duplicates\n",
    "def check_duplicates(df):\n",
    "    print(\"Duplicate Rows:\")\n",
    "    print(df[df.duplicated()])\n",
    "\n",
    "# 14. Drop Duplicates\n",
    "def drop_duplicates_example(df):\n",
    "    df = df.drop_duplicates()\n",
    "    print(\"Data After Dropping Duplicates:\")\n",
    "    print(df.head())\n",
    "\n",
    "# 15. Rename Columns\n",
    "def rename_columns_example(df):\n",
    "    df = df.rename(columns={'old_name': 'new_name'})\n",
    "    print(\"Renamed Columns:\")\n",
    "    print(df.head())\n",
    "\n",
    "# 16. Random Sampling\n",
    "def sample_example(df):\n",
    "    sample = df.sample(n=5)\n",
    "    print(\"Random Sample of Rows:\")\n",
    "    print(sample)\n",
    "\n",
    "# 17. Value Counts\n",
    "def value_counts_example(df):\n",
    "    print(\"Value Counts:\")\n",
    "    print(df['column_name'].value_counts())\n",
    "\n",
    "# 18. Melt DataFrame\n",
    "def melt_example(df):\n",
    "    melted = pd.melt(df, id_vars=['id'], value_vars=['col1', 'col2'])\n",
    "    print(\"Melted DataFrame:\")\n",
    "    print(melted.head())\n",
    "\n",
    "# 19. Correlation Matrix\n",
    "def correlation_example(df):\n",
    "    correlation = df.corr()\n",
    "    print(\"Correlation Matrix:\")\n",
    "    print(correlation)\n",
    "\n",
    "# 20. Export to CSV\n",
    "def to_csv_example(df):\n",
    "    df.to_csv('output.csv', index=False)\n",
    "    print(\"DataFrame exported to 'output.csv'\")\n",
    "\n",
    "# Example Usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Example to demonstrate functions (requires valid CSV and columns)\n",
    "    try:\n",
    "        df = pd.read_csv('/mnt/data/survey_results_public.csv')\n",
    "        read_csv_example()\n",
    "        head_example(df)\n",
    "        info_example(df)\n",
    "        describe_example(df)\n",
    "        check_missing_values(df)\n",
    "        # Uncomment below lines after ensuring the column names exist in your data\n",
    "        # fill_missing_values(df)\n",
    "        # group_by_example(df)\n",
    "        # sort_values_example(df)\n",
    "        # apply_example(df)\n",
    "        # Example merge (requires second DataFrame df2)\n",
    "        # merge_example(df, df2)\n",
    "        # Additional examples\n",
    "        # concat_example(df, df2)\n",
    "        # pivot_table_example(df)\n",
    "        # check_duplicates(df)\n",
    "        # drop_duplicates_example(df)\n",
    "        # rename_columns_example(df)\n",
    "        # sample_example(df)\n",
    "        # value_counts_example(df)\n",
    "        # melt_example(df)\n",
    "        # correlation_example(df)\n",
    "        # to_csv_example(df)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Please provide a valid 'data.csv' file in the working directory.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sansui",
   "language": "python",
   "name": "sansui"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
